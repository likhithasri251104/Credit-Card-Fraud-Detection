# ğŸ’³ AI-Based Credit Card Fraud Detection System

A machine learning project for detecting fraudulent credit card transactions using classification algorithms. This solution uses real-world, imbalanced data and incorporates various techniques including preprocessing, resampling (SMOTE), and model evaluation.

---

## ğŸ“Œ Project Overview

Credit card fraud is a significant challenge in financial security. This project utilizes supervised machine learning to detect fraudulent transactions. It involves:

- Data cleaning and preprocessing
- Handling imbalanced datasets using SMOTE
- Feature analysis and visualization
- Model training with classifiers such as Logistic Regression, KNN, XGBoost, Decision Tree, and Random Forest
- Hyperparameter tuning and performance evaluation

---

## ğŸ“ Dataset

This project uses the [Kaggle Credit Card Fraud Detection Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud) which contains transactions made by European cardholders in September 2013.

- **Rows:** 284,807
- **Features:** 30 (V1-V28 are PCA components, plus `Time`, `Amount`, and `Class`)
- **Class:** 0 for non-fraud, 1 for fraud

---

## ğŸ“‚ Project Structure

fraud-detection/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ creditcard.csv
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ credit_card_fraud_detection.ipynb
â”œâ”€â”€ models/
â”‚ â””â”€â”€ trained_models.pkl
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt



---

## ğŸ”§ Installation

### Prerequisites

- Python 3.8 or higher
- pip

### Clone the repository

```bash
git clone https://github.com/yourusername/fraud-detection.git
cd fraud-detection



ğŸ“Š Features Covered
ğŸ§¼ Data Cleaning: Removal of null values and duplicates.

ğŸ“ˆ Exploratory Data Analysis (EDA): Histograms, box plots, correlation heatmaps.

âš–ï¸ Imbalance Handling: SMOTE (Synthetic Minority Over-sampling Technique).

ğŸ“¦ Feature Scaling: Using standardization and normalization.

ğŸ§  Model Training: Multiple classifiers (Logistic Regression, KNN, Decision Tree, XGBoost, Random Forest).

ğŸ” Model Evaluation: Accuracy, Precision, Recall, F1-score, Confusion Matrix.

ğŸ”§ Hyperparameter Tuning: GridSearchCV for optimal performance.

ğŸ§ª Model Performance
Each classifier is evaluated using:

Accuracy

Precision

Recall

F1 Score

Confusion Matrix

The model that performs best in terms of Recall and F1-Score is typically chosen for production use.

ğŸ“‰ Sample Output (Confusion Matrix)

Confusion Matrix for XGBoost:
[[85267    33]
 [   19   123]]
Accuracy: 0.9994
Precision: 0.7885
Recall: 0.8662
F1 Score: 0.8257
ğŸ“ˆ Visualizations
Correlation Heatmaps

Feature importance

Class Distribution

Boxplots for Outlier Detection

Confusion Matrices for each model

ğŸ§  Models Used
âœ… Logistic Regression

âœ… K-Nearest Neighbors

âœ… Decision Tree

âœ… Random Forest

âœ… XGBoost

ğŸ“Š Libraries & Tools
pandas, numpy â€“ Data Manipulation

matplotlib, seaborn â€“ Data Visualization

scikit-learn â€“ Machine Learning models and tools

xgboost â€“ Gradient boosting framework

imblearn â€“ SMOTE for imbalance handling

